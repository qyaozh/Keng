<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Plan Sample Size</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Plan Sample Size</h1>



<p>The significance of the unique effect of one or a set of predictors
in the regression model is determined by (1) PRE (Proportional Reduction
in Error, also called partial <em>eta_squared</em> in ANOVA, or partial
<em>R_squared</em> in regression), (2) number of parameters in the
regression model, and (3) sample size. As a result, given <em>PRE</em>,
the number of parameters in the regression model, and expected
statistical power, we can plan the sample size for one or a set of
predictors to reach the expected statistical power (usually 0.80) and
the expected significance level (usually 0.05). This is just
<code>power_lm()</code>’s mission.</p>
<p>To compare the power of r<sup>2</sup> and PRE, <code>Keng</code> also
gives <code>power_r()</code> to conduct power analysis for Pearson’s
<em>r</em>. <code>power_r()</code> has readable arguments and is easy to
use, hence is not detailed in vignettes.</p>
<div id="understand-the-arguments-of-power_lm" class="section level2">
<h2>Understand the arguments of <code>power_lm()</code></h2>
<p>Among the arguments of <code>power_lm()</code>, PRE, PC, and PA merit
further explanation.</p>
<div id="pre" class="section level3">
<h3><code>PRE</code></h3>
<p><em>PRE</em> is partial <em>R_squared</em>. Partial
<em>R_squared</em> is the square of the partial correlation. You could
calculate <em>PRE</em> from the partial correlation. Other statistical
software or R packages often plan sample size for regression models
through Cohen’s <em>f_squared</em>, or its square root, Cohen’s
<em>f</em>. <code>power_lm()</code> use <em>PRE</em> here because
<em>PRE</em> and its square root, partial correlation, are more
meaningful. The partial correlation is the net correlation between the
outcome of regression (e.g., depression) and the predictor (e.g.,
problem-focused coping) or set of predictors (e.g., the dummy codes of
class) of interest. Put differently, the partial correlation is the pure
correlation between the outcome and the predictor or set of predictors
of interest after controlling for all other predictors, no matter how
many they are. We should give a nice guess about the partial
correlation. For example, we may guess that, after controlling for other
predictors, the partial correlation between the outcome depression and
the predictor problem-focused coping is 0.2, then <em>PRE</em> =
0.2<sup>2</sup> = 0.04. You may get the effect size Cohen’s
<em>f_squared</em> or <em>f</em> of problem-focused coping predicting
depression, and in this case you could convert Cohen’s
<em>f_squared</em> or <em>f</em> to <em>PRE</em>. <code>Keng</code>
provides a function <code>calc_PRE()</code> to help users to convert the
partial correlation <code>r_p</code>, or <code>f_squared</code> or
<code>f</code> to <em>PRE</em>.</p>
</div>
<div id="pa-and-pc" class="section level3">
<h3><code>PA</code> and <code>PC</code></h3>
<p>Suppose that your regression model has m predictors totally. This
model is the augmented model (Model A), and has both the focal
predictors (e.g., gender, the dummy codes of class) and other
less-important predictors like covariates. The number of parameters of
this augmented model (Model A), <code>PA</code>, is m + 1, since the
intercept is also a parameter. <code>PA</code> should be at least 1.</p>
<p>The model without the focal predictors is the compact model (Model
C). Suppose that the number of the focal predictors is k, the resulting
number of parameters of the compact model (Model C), <code>PC</code>, is
m + 1 - k. <code>PC</code> should be at least 0.</p>
<p>Note that <code>power_lm()</code> follows Aberson’s (2019), and the
planned sample size is more conservative than other statistical software
like G*power. However, the difference is small and negligible.</p>
</div>
</div>
<div id="application" class="section level2">
<h2>Application</h2>
<p>Given that regression analysis is equivalent to t-test and ANOVA,
<code>power_lm()</code> could plan the sample size for perhaps all
common research designs.</p>
<div id="a-set-of-predictors" class="section level3">
<h3>A set of predictors</h3>
<p>You may be interested in the power and required sample size of the
full regression model, you could treat all predictors as a set. The
Model C is the intercept-only model, hence PC = 1. Suppose your
regression model has m predictors, hence PA = m + 1.</p>
<p>m predictors’ total PRE is actually R<sup>2</sup>. Assuming m
predictors’ total PRE is 0.02, m is 10, we plan the sample size using
the following code:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(Keng)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">power_lm</span>(<span class="at">PRE =</span> <span class="fl">0.02</span>, <span class="at">PC =</span> <span class="dv">1</span>, <span class="at">PA =</span> <span class="dv">11</span>)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co">#&gt; -- Given ---------------------------</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co">#&gt; PRE = 0.02</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#&gt; f_squared = 0.02040816</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#&gt; PC = 1</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#&gt; PA = 11</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co">#&gt; sig_level = 0.05</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co">#&gt; -- Post-hoc power analysis --------</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co">#&gt; n = NULL</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co">#&gt; power_post = NULL</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co">#&gt; -- Sample size planning -----------</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co">#&gt; Expected power = 0.8</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co">#&gt; Minimum sample size = 816</span></span></code></pre></div>
<p>As shown above, this design needs at least 816
cases/observations.</p>
</div>
<div id="a-continuous-predictor" class="section level3">
<h3>A continuous predictor</h3>
<p>You may be interested in the power and required sample size of one
continuous predictor. Suppose your regression model has m predictors, in
this case PA = m + 1, PC = (m + 1) - 1.</p>
</div>
<div id="moderation-model" class="section level3">
<h3>Moderation model</h3>
<p>You may be interested in the two-way moderation model. In the two-way
moderation model, the focal predictor is actually the two-way
interaction term. Suppose your regression model has m predictors, in
this case PA = m + 1, PC = (m + 1) - 1.</p>
<p>You may be interested in the three-way moderation model. In the
three-way moderation model, the focal predictors are two two-way
interaction terms and one three-way interaction term. Suppose your
regression model has m predictors, in this case PA = m + 1, PC = (m + 1)
- 3.</p>
</div>
<div id="one-sample-t--test-or-an-intercept-only-regression" class="section level3">
<h3>One-sample <em>t</em> -test or an intercept-only regression</h3>
<p>If you are interested in the difference between the mean of one group
and 0, you may turn to the one-sample <em>t</em> -test. Or, you could
establish an intercept-only model. Then the focal parameter is the
intercept. In this case PA = 1, PC = 0.</p>
<p>Note that in this case you must use the <strong>CORRECT</strong>
<em>PRE</em> to yield the correct power and planned sample size. Do not
compute <em>PRE</em> from Cohen’s one-sample <em>d</em> ; instead,
compute <em>PRE</em> from the <em>t</em> value of the one-sample
<em>t</em> -test by converting <em>t</em> to <em>r</em>, and then
converting <em>r</em> to <em>PRE</em>. You could also compute the
correct <em>PRE</em> using <code>compare_lm()</code> function.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">library</span>(Keng)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;depress&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># WRONG PRE for the one-sample t-test</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>(Cohens_d <span class="ot">&lt;-</span> effectsize<span class="sc">::</span><span class="fu">cohens_d</span>(dm1 <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> depress)<span class="sc">$</span>Cohens_d)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">#&gt; [1] 4.985268</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>(r_from_d <span class="ot">&lt;-</span> effectsize<span class="sc">::</span><span class="fu">d_to_r</span>(Cohens_d, <span class="at">n1 =</span> <span class="dv">94</span>))</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co">#&gt; [1] 0.9287831</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>(PRE_from_d <span class="ot">&lt;-</span> r_from_d<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="co">#&gt; [1] 0.862638</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co"># CORRECT PRE for the one-sample t-test</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">t.test</span>(dm1 <span class="sc">~</span> <span class="dv">1</span>, depress)</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>(r_from_t <span class="ot">&lt;-</span> effectsize<span class="sc">::</span><span class="fu">t_to_r</span>(<span class="at">t =</span> out<span class="sc">$</span>statistic, <span class="at">df_error =</span> out<span class="sc">$</span>parameter)<span class="sc">$</span>r)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="co">#&gt; [1] 0.9806709</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>(PRE_from_t <span class="ot">&lt;-</span> r_from_t<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="co">#&gt; [1] 0.9617153</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="co"># PRE from lm()</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>fit0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(dm1 <span class="sc">~</span> <span class="dv">0</span>, depress)</span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(dm1 <span class="sc">~</span> <span class="dv">1</span>, depress)</span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="fu">compare_lm</span>(fit0, fit1)[<span class="dv">7</span>, <span class="dv">4</span>]</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a><span class="co">#&gt; [1] NA</span></span></code></pre></div>
</div>
<div id="two-sample-t--test-or-a-binary-predictor" class="section level3">
<h3>Two-sample <em>t</em> -test or a binary predictor</h3>
<p>If you are interested in the difference between two groups (e.g.,
experimental vs control), you may turn to the <em>t</em> -test. Or, you
could treat the group variable as a binary predictor and conduct
regression analysis. Then the focal predictor is the binary group
predictor. Suppose your regression model has m predictors, in this case
PA = m + 1, PC = (m + 1) - 1.</p>
</div>
<div id="anova-or-a-multicategorical-predictor" class="section level3">
<h3>ANOVA or a multicategorical predictor</h3>
<p>If you are interested in the difference between multiple groups, you
may turn to ANOVA. Or, you could treat the group variable as a
multicategorical independent variable. Then you could code it using a
coding schema like dummy coding. No matter which coding schema you use,
for a multicategorical independent variable with j levels, it should be
coded into (j - 1) predictors, which are the set of focal predictors.
Suppose your regression model has m predictors, among which there are (j
- 1) codes, in this case PA = m + 1, PC = (m + 1) - (j - 1).</p>
</div>
<div id="anova-concerning-repeated-measures" class="section level3">
<h3>ANOVA concerning repeated measures</h3>
<p>If you are interested in the outcome that were repeatedly measured,
you may turn to repeated-measures-ANOVA. In essence,
repeated-measures-ANOVA computes the difference score of interest
(contrasts), and then conducts between-factor ANOVA. Similarly, you
could compute the difference score of interest, and then conduct
regression analyses.</p>
<p>A special case is there is no between-subject factor. Under this
circumstance, treat the difference score as the outcome and establish an
intercept-only model like one-sample <em>t</em> -test.</p>
</div>
</div>
<div id="reference" class="section level2">
<h2>Reference</h2>
<p>Aberson, C. L. (2019). <em>Applied power analysis for the behavioral
sciences</em>. Routledge.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
